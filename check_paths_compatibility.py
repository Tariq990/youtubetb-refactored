#!/usr/bin/env python3
"""
ØªØ­Ù‚Ù‚ Ù…Ù† ØªÙˆØ§ÙÙ‚ Ø£Ù…Ø§ÙƒÙ† Ø§Ù„Ø­ÙØ¸ Ø¨ÙŠÙ† cookies_helper.py Ùˆ pipeline
Check compatibility between cookies_helper.py save locations and pipeline read locations
"""

from pathlib import Path
import json

# Import from cookies_helper
from cookies_helper import COOKIES_PATHS, API_KEYS_PATHS, SECRETS_DIR

print("="*80)
print("ğŸ” ØªØ­Ù„ÙŠÙ„ ØªÙˆØ§ÙÙ‚ Ø£Ù…Ø§ÙƒÙ† Ø§Ù„ØªØ®Ø²ÙŠÙ† / Storage Locations Compatibility Analysis")
print("="*80)

# ==============================================================================
# PART 1: COOKIES - Where cookies_helper saves vs where pipeline reads
# ==============================================================================
print("\nğŸ“‹ PART 1: COOKIES (YouTube)")
print("-"*80)

# Where cookies_helper SAVES cookies
print("\nâœ… WHERE cookies_helper.py SAVES:")
print("   Function: add_cookies() â†’ save_to_file()")
print("   Priority order (uses FIRST empty slot):")
for i, path in enumerate(COOKIES_PATHS, 1):
    status = "âœ“ EXISTS" if path.exists() else "âœ— NOT FOUND"
    size = f"({path.stat().st_size:,} bytes)" if path.exists() else ""
    print(f"   [{i}] {path} {status} {size}")

# Where pipeline READS cookies
print("\nğŸ“– WHERE PIPELINE READS:")
print("   File: src/infrastructure/adapters/transcribe.py")
print("   Variable: cookie_paths (lines 525-530)")
print("   Search order:")

pipeline_cookies = [
    Path("secrets/cookies.txt"),
    Path("secrets/cookies_1.txt"),
    Path("secrets/cookies_2.txt"),
    Path("secrets/cookies_3.txt"),
    Path("cookies.txt")
]

for i, rel_path in enumerate(pipeline_cookies, 1):
    abs_path = Path(__file__).parent / rel_path
    status = "âœ“ EXISTS" if abs_path.exists() else "âœ— NOT FOUND"
    print(f"   [{i}] {rel_path} {status}")

# Check compatibility
print("\nğŸ” COMPATIBILITY CHECK:")
helper_set = {p.resolve() for p in COOKIES_PATHS}
pipeline_set = {(Path(__file__).parent / p).resolve() for p in pipeline_cookies}

if helper_set == pipeline_set:
    print("   âœ… PERFECT MATCH! All paths identical.")
else:
    missing = pipeline_set - helper_set
    extra = helper_set - pipeline_set
    if missing:
        print(f"   âš ï¸  Pipeline reads from {len(missing)} locations NOT in cookies_helper:")
        for p in missing:
            print(f"       â€¢ {p}")
    if extra:
        print(f"   âš ï¸  cookies_helper saves to {len(extra)} locations NOT read by pipeline:")
        for p in extra:
            print(f"       â€¢ {p}")

# ==============================================================================
# PART 2: GEMINI API KEYS - Where cookies_helper saves vs where pipeline reads
# ==============================================================================
print("\n\nğŸ“‹ PART 2: GEMINI API KEYS")
print("-"*80)

# Where cookies_helper SAVES Gemini keys
print("\nâœ… WHERE cookies_helper.py SAVES:")
print("   Function: add_gemini_api() â†’ Choice [1]")
print("   Default location:")
gemini_save_path = SECRETS_DIR / "api_keys.txt"
status = "âœ“ EXISTS" if gemini_save_path.exists() else "âœ— NOT FOUND"
print(f"   â€¢ {gemini_save_path} {status}")

print("\n   Alternative location (Choice [2]):")
env_path = SECRETS_DIR / ".env"
status = "âœ“ EXISTS" if env_path.exists() else "âœ— NOT FOUND"
print(f"   â€¢ {env_path} (GEMINI_API_KEY=...) {status}")

# Where pipeline READS Gemini keys
print("\nğŸ“– WHERE PIPELINE READS:")
print("   File: src/infrastructure/adapters/process.py")
print("   Function: _load_gemini_model() (lines 156-180)")
print("   Search order:")
print("   [1] Environment variable: GEMINI_API_KEY")
print("   [2] secrets/api_keys.txt (multi-line file)")
print("   [3] secrets/api_key.txt (single key)")
print("   [4] .env file (GEMINI_API_KEY=...)")

print("\nğŸ” COMPATIBILITY CHECK:")
print("   âœ… cookies_helper saves to: secrets/api_keys.txt")
print("   âœ… Pipeline reads from: secrets/api_keys.txt (Priority 2)")
print("   âœ… COMPATIBLE! Pipeline WILL find keys saved by cookies_helper")

# ==============================================================================
# PART 3: YOUTUBE API KEYS - Critical compatibility check
# ==============================================================================
print("\n\nğŸ“‹ PART 3: YOUTUBE API KEYS âš ï¸  CRITICAL")
print("-"*80)

# Where cookies_helper SAVES YouTube keys (AFTER FIX)
print("\nâœ… WHERE cookies_helper.py SAVES:")
print("   Function: add_youtube_api() â†’ Choice [1]")
youtube_save_path = SECRETS_DIR / "api_keys.txt"  # OLD DEFAULT
status = "âœ“ EXISTS" if youtube_save_path.exists() else "âœ— NOT FOUND"
print(f"   â€¢ {youtube_save_path} {status}")
print("      ^ âš ï¸  WARNING: This is SHARED with Gemini!")

# Where pipeline READS YouTube keys
print("\nğŸ“– WHERE PIPELINE READS:")
print("   File: src/infrastructure/adapters/search.py")
print("   Function: _load_all_youtube_api_keys() (lines 45-85)")
print("   Search order:")
print("   [1] Environment variable: YT_API_KEY or YOUTUBE_API_KEY")
print("   [2] secrets/api_keys.txt (SHARED FILE - reads ALL keys)")
print("   [3] secrets/api_key.txt (single key)")

print("\nğŸ” COMPATIBILITY CHECK:")
print("   âœ… cookies_helper saves to: secrets/api_keys.txt")
print("   âœ… Pipeline reads from: secrets/api_keys.txt (Priority 2)")
print("   âœ… COMPATIBLE! Pipeline WILL find keys saved by cookies_helper")
print("\n   âš ï¸  PROBLEM: No dedicated youtube/ subfolder support!")
print("      â€¢ cookies_helper has: secrets/youtube/api_keys.txt in API_KEYS_PATHS")
print("      â€¢ But add_youtube_api() saves to: secrets/api_keys.txt (shared)")
print("      â€¢ Pipeline does NOT check secrets/youtube/api_keys.txt")

# Check if dedicated youtube folder exists
youtube_dedicated = SECRETS_DIR / "youtube" / "api_keys.txt"
if youtube_dedicated.exists():
    print(f"\n   ğŸ“ Found: {youtube_dedicated}")
    print(f"      âš ï¸  This file exists but pipeline does NOT read from it!")
    print(f"      ğŸ’¡ Solution: Copy keys to secrets/api_keys.txt")

# ==============================================================================
# PART 4: PEXELS API KEYS
# ==============================================================================
print("\n\nğŸ“‹ PART 4: PEXELS API KEYS")
print("-"*80)

# Where cookies_helper SAVES Pexels keys
print("\nâœ… WHERE cookies_helper.py SAVES:")
print("   Function: add_pexels_api() â†’ Choice [1]")
pexels_save_path = SECRETS_DIR / "pexels_key.txt"
status = "âœ“ EXISTS" if pexels_save_path.exists() else "âœ— NOT FOUND"
print(f"   â€¢ {pexels_save_path} {status}")

# Where pipeline READS Pexels keys
print("\nğŸ“– WHERE PIPELINE READS:")
print("   File: src/infrastructure/adapters/shorts_generator.py")
print("   Function: _load_pexels_api_key() (lines 560-600)")
print("   Search order:")
print("   [1] Environment variable: PEXELS_API_KEY")
print("   [2] secrets/pexels_key.txt")
print("   [3] secrets/pexels/api_key.txt")
print("   [4] secrets/api_keys.txt (shared)")
print("   [5] .env file")

print("\nğŸ” COMPATIBILITY CHECK:")
print("   âœ… cookies_helper saves to: secrets/pexels_key.txt")
print("   âœ… Pipeline reads from: secrets/pexels_key.txt (Priority 2)")
print("   âœ… COMPATIBLE! Pipeline WILL find keys saved by cookies_helper")

# ==============================================================================
# FINAL SUMMARY
# ==============================================================================
print("\n\n" + "="*80)
print("ğŸ“Š FINAL SUMMARY / Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ")
print("="*80)

summary = {
    "cookies": {
        "compatible": True,
        "save_to": str(COOKIES_PATHS[0]),
        "pipeline_reads": "secrets/cookies.txt (Priority 1)",
        "status": "âœ… FULLY COMPATIBLE"
    },
    "gemini": {
        "compatible": True,
        "save_to": "secrets/api_keys.txt",
        "pipeline_reads": "secrets/api_keys.txt (Priority 2)",
        "status": "âœ… FULLY COMPATIBLE"
    },
    "youtube": {
        "compatible": True,
        "save_to": "secrets/api_keys.txt",
        "pipeline_reads": "secrets/api_keys.txt (Priority 2)",
        "status": "âš ï¸  COMPATIBLE BUT PROBLEMATIC",
        "issue": "Pipeline does NOT read from secrets/youtube/api_keys.txt",
        "solution": "Keys must be in secrets/api_keys.txt (shared with Gemini)"
    },
    "pexels": {
        "compatible": True,
        "save_to": "secrets/pexels_key.txt",
        "pipeline_reads": "secrets/pexels_key.txt (Priority 2)",
        "status": "âœ… FULLY COMPATIBLE"
    }
}

print("\n1. ğŸª COOKIES:")
print(f"   {summary['cookies']['status']}")
print(f"   â€¢ cookies_helper saves to: {summary['cookies']['save_to']}")
print(f"   â€¢ Pipeline reads from: {summary['cookies']['pipeline_reads']}")

print("\n2. ğŸ¤– GEMINI API:")
print(f"   {summary['gemini']['status']}")
print(f"   â€¢ cookies_helper saves to: {summary['gemini']['save_to']}")
print(f"   â€¢ Pipeline reads from: {summary['gemini']['pipeline_reads']}")

print("\n3. ğŸ“º YOUTUBE API:")
print(f"   {summary['youtube']['status']}")
print(f"   â€¢ cookies_helper saves to: {summary['youtube']['save_to']}")
print(f"   â€¢ Pipeline reads from: {summary['youtube']['pipeline_reads']}")
if 'issue' in summary['youtube']:
    print(f"   âš ï¸  {summary['youtube']['issue']}")
    print(f"   ğŸ’¡ {summary['youtube']['solution']}")

print("\n4. ğŸ¬ PEXELS API:")
print(f"   {summary['pexels']['status']}")
print(f"   â€¢ cookies_helper saves to: {summary['pexels']['save_to']}")
print(f"   â€¢ Pipeline reads from: {summary['pexels']['pipeline_reads']}")

# Overall verdict
print("\n" + "="*80)
print("ğŸ¯ OVERALL VERDICT / Ø§Ù„Ø­ÙƒÙ… Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ")
print("="*80)
print("\nâœ… Ù†Ø¹Ù…ØŒ Ø§Ù„Ø£Ø¯Ø§Ø© ØªØ­ÙØ¸ ÙÙŠ Ø§Ù„Ø£Ù…Ø§ÙƒÙ† Ø§Ù„ØµØ­ÙŠØ­Ø©!")
print("   Yes, cookies_helper.py saves to CORRECT locations!")
print("\nâœ… Ø§Ù„Ù€ Pipeline ÙŠÙ…ÙƒÙ†Ù‡ Ù‚Ø±Ø§Ø¡Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©")
print("   Pipeline CAN read all saved keys and cookies")
print("\nâš ï¸  Ù…Ù„Ø§Ø­Ø¸Ø© ÙˆØ§Ø­Ø¯Ø©: Ù…ÙØ§ØªÙŠØ­ YouTube ÙÙŠ Ù…Ù„Ù Ù…Ø´ØªØ±Ùƒ Ù…Ø¹ Gemini")
print("   One note: YouTube keys in SHARED file with Gemini")
print("   (secrets/api_keys.txt - not a problem, just shared)")

# Save report
report_path = Path("compatibility_report.json")
with open(report_path, "w", encoding="utf-8") as f:
    json.dump(summary, f, indent=2, ensure_ascii=False)
print(f"\nğŸ“„ Detailed report saved to: {report_path}")

print("\n" + "="*80)
