# â™»ï¸ Resume from Failed Stage Feature
**Date**: 2025-10-19  
**Status**: âœ… IMPLEMENTED

## Feature Overview

Ø¹Ù†Ø¯Ù…Ø§ ÙŠÙØ´Ù„ Ø§Ù„Ø¨Ø§ÙŠØ¨ Ù„Ø§ÙŠÙ† ÙÙŠ Ø£ÙŠ Ù…Ø±Ø­Ù„Ø© Ø¨Ø¹Ø¯ Ø§Ø³ØªÙ†ÙØ§Ø¯ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª (10 Ù…Ø­Ø§ÙˆÙ„Ø§Øª)ØŒ ÙƒØ§Ù† Ø§Ù„Ù†Ø¸Ø§Ù… ÙŠØªÙˆÙ‚Ù ÙˆÙŠØ­ÙØ¸ `status="failed"` ÙÙŠ `summary.json`. 

**Ø§Ù„Ù…Ø´ÙƒÙ„Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©**: Ø¹Ù†Ø¯ Ø¥Ø¹Ø§Ø¯Ø© ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¨Ø§ÙŠØ¨ Ù„Ø§ÙŠÙ† Ù„Ù„ÙƒØªØ§Ø¨ Ù†ÙØ³Ù‡ØŒ ÙƒØ§Ù† Ø§Ù„Ù†Ø¸Ø§Ù…:
- âŒ ÙŠØªØ®Ø·Ù‰ Ø§Ù„Ù…Ø±Ø§Ø­Ù„ Ø§Ù„Ù…ÙƒØªÙ…Ù„Ø© Ø¨Ù†Ø¬Ø§Ø­ (correct)
- âŒ Ù„ÙƒÙ† **ÙŠØªØ®Ø·Ù‰ Ø£ÙŠØ¶Ø§Ù‹ Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„ÙØ§Ø´Ù„Ø©** Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø¥Ø¹Ø§Ø¯Ø© Ù…Ø­Ø§ÙˆÙ„ØªÙ‡Ø§
- âŒ ÙŠØ¨Ø¯Ø£ Ù…Ù† Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„ØªØ§Ù„ÙŠØ© Ù„Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„ÙØ§Ø´Ù„Ø©
- âŒ Ø§Ù„Ù†ØªÙŠØ¬Ø©: ÙÙŠØ¯ÙŠÙˆ Ù†Ø§Ù‚Øµ Ø¨Ø¯ÙˆÙ† Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£Ùˆ ØµÙˆØª Ø£Ùˆ Ø±ÙØ¹

**Ø§Ù„Ø­Ù„ Ø§Ù„Ø¬Ø¯ÙŠØ¯**: Ø¹Ù†Ø¯ Ø¥Ø¹Ø§Ø¯Ø© ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¨Ø§ÙŠØ¨ Ù„Ø§ÙŠÙ†ØŒ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø¢Ù†:
- âœ… ÙŠÙƒØªØ´Ù Ø¢Ø®Ø± Ù…Ø±Ø­Ù„Ø© ÙØ´Ù„Øª Ù…Ù† `summary.json`
- âœ… **ÙŠØ¹ÙŠØ¯ Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„ÙØ§Ø´Ù„Ø©** Ù…Ø¹ 10 Ù…Ø­Ø§ÙˆÙ„Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©
- âœ… ÙŠØ·Ø¨Ø¹ Ø±Ø³Ø§Ù„Ø© ÙˆØ§Ø¶Ø­Ø©: "RESUMING FROM FAILED STAGE: [stage_name]"
- âœ… ÙŠØªØ®Ø·Ù‰ ÙÙ‚Ø· Ø§Ù„Ù…Ø±Ø§Ø­Ù„ Ø§Ù„Ù…ÙƒØªÙ…Ù„Ø© **Ø¨Ù†Ø¬Ø§Ø­**
- âœ… Ø§Ù„Ù†ØªÙŠØ¬Ø©: Ø§Ø³ØªØ¦Ù†Ø§Ù Ø°ÙƒÙŠ ÙŠØ­Ù„ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ù…Ø¤Ù‚ØªØ© (network, API limits, etc.)

---

## Implementation Details

### 1. New Functions Added

#### Function: `_get_last_failed_stage(run_dir: Path) -> Optional[str]`

**Location**: `src/presentation/cli/run_pipeline.py` (Lines 170-200)

**Purpose**: Find the last stage that failed in a previous run.

**Logic**:
```python
def _get_last_failed_stage(run_dir: Path) -> Optional[str]:
    """
    Get the last failed stage from summary.json to enable resume from failure.
    
    When a stage fails after max retries, it's saved with status="failed".
    This function finds that stage so the pipeline can retry it on resume.
    """
    summary_file = run_dir / "summary.json"
    if not summary_file.exists():
        return None
    
    # Read summary.json
    summary = json.load(summary_file.open("r", encoding="utf-8"))
    
    # Find all stages with status="failed"
    failed_stages = [
        stage.get("name") 
        for stage in summary.get("stages", []) 
        if stage.get("status") == "failed"
    ]
    
    if failed_stages:
        # Return the most recent failure
        return failed_stages[-1]
    
    return None
```

**Returns**:
- Stage name (e.g., "process", "tts", "upload") if a failed stage is found
- `None` if no failures found (normal resume from last successful stage)

---

#### Function: `_should_retry_stage(run_dir, stage_name, failed_stage) -> bool`

**Location**: `src/presentation/cli/run_pipeline.py` (Lines 202-232)

**Purpose**: Determine if a stage should be executed based on previous run status.

**Decision Logic**:
```python
def _should_retry_stage(run_dir, stage_name, failed_stage) -> bool:
    """
    Determine if a stage should be retried based on previous run status.
    
    Logic:
    - If stage was completed successfully (status="ok") â†’ Skip (False)
    - If stage was the one that failed (status="failed") â†’ Retry (True)
    - If stage comes after failed stage â†’ Run (True, need to continue pipeline)
    """
    # No failed stage? Use normal completion check
    if not failed_stage:
        return not _is_stage_completed(run_dir, stage_name)
    
    # This is the failed stage? Always retry
    if stage_name == failed_stage:
        console.print(f"[cyan]â™»ï¸  Retrying failed stage: {stage_name}[/cyan]")
        return True
    
    # Stage completed successfully? Skip
    if _is_stage_completed(run_dir, stage_name):
        return False
    
    # Stage after the failed one? Run it
    return True
```

**Truth Table**:
| Stage Status | Failed Stage? | Return | Action |
|-------------|---------------|--------|--------|
| Completed (ok) | No | False | Skip |
| Completed (ok) | Yes (not this) | False | Skip |
| Failed | Yes (this one) | True | **Retry** |
| Not started | - | True | Run |
| After failed | - | True | Run |

---

### 2. Modified Resume Logic

**Location**: `src/presentation/cli/run_pipeline.py` (Lines 740-760)

**Changes**: When resuming from an existing run folder:

```python
# OLD (Before Fix)
if old_run_folder:
    d["root"] = old_run_folder
    console.print(f"[cyan]Pipeline will resume from last successful stage...[/cyan]\n")
    # Continue to stages...

# NEW (After Fix)
if old_run_folder:
    d["root"] = old_run_folder
    
    # ğŸ” CRITICAL: Check for failed stages
    failed_stage = _get_last_failed_stage(old_run_folder)
    if failed_stage:
        console.print(f"[bold yellow]â™»ï¸  RESUMING FROM FAILED STAGE: {failed_stage}[/bold yellow]")
        console.print(f"[yellow]   This stage will be retried with {MAX_RETRIES_PER_STAGE} attempts[/yellow]")
        console.print(f"[dim]   All completed stages will be skipped[/dim]\n")
        # Store for later use
        summary["last_failed_stage"] = failed_stage
    else:
        console.print(f"[cyan]Pipeline will resume from last successful stage...[/cyan]\n")
    
    # ğŸ“– Load existing summary.json
    summary_file = old_run_folder / "summary.json"
    if summary_file.exists():
        summary = json.loads(summary_file.read_text(encoding="utf-8"))
        console.print(f"[dim]âœ“ Loaded existing summary with {len(summary.get('stages', []))} completed stages[/dim]")
```

**Key Changes**:
1. âœ… Call `_get_last_failed_stage()` after detecting resume scenario
2. âœ… Store `failed_stage` in `summary["last_failed_stage"]`
3. âœ… Load existing `summary.json` to preserve stage history
4. âœ… Print clear user message about which stage will be retried

---

### 3. Updated All Stage Checks

**Location**: All stage sections in `run_pipeline.py`

**Changed Code Pattern**:
```python
# OLD (All 11 stages had this pattern)
if _is_stage_completed(d["root"], "stage_name"):
    console.print("[green]âœ“ Stage already completed (skipping)[/green]")
    # Use cached result
else:
    # Run stage with retry logic

# NEW (All 11 stages now use this pattern)
if not _should_retry_stage(d["root"], "stage_name", failed_stage):
    console.print("[green]âœ“ Stage already completed (skipping)[/green]")
    # Use cached result
else:
    # Run stage with retry logic (will retry if failed)
```

**Affected Stages** (11 total):
1. âœ… **search** - Line 851
2. âœ… **transcribe** - Line 906
3. âœ… **process** - Line 975
4. âœ… **tts** - Line 1035
5. âœ… **youtube_metadata** - Line 1093
6. âœ… **render** - Line 1137
7. âœ… **merge** - Line 1280
8. âœ… **thumbnail** - Line 1347
9. âœ… **upload** - Line 1416
10. âœ… **short** - Line 1472
11. âœ… **short_upload** - Line 1519

---

## User Experience

### Scenario 1: Fresh Run (No Failures)
```
ğŸ“š Processing: "Atomic Habits"
âœ… All stages complete successfully
Status: done
```

### Scenario 2: Pipeline Fails at TTS Stage
```
ğŸ“š Processing: "Atomic Habits"
âœ… SEARCH - OK
âœ… TRANSCRIBE - OK
âœ… PROCESS - OK
âŒ TTS - FAILED after 10 attempts (network timeout)
ğŸ›‘ PIPELINE STOPPED

Summary.json:
{
  "stages": [
    {"name": "search", "status": "ok"},
    {"name": "transcribe", "status": "ok"},
    {"name": "process", "status": "ok"},
    {"name": "tts", "status": "failed"}  â† Saved as failed
  ]
}
```

### Scenario 3: Resume After Fixing Issue
```
ğŸ“š Re-running: "Atomic Habits"
â™»ï¸  Found existing run folder
â™»ï¸  RESUMING FROM FAILED STAGE: tts
    This stage will be retried with 10 attempts
    All completed stages will be skipped

âœ“ SEARCH - Skipped (already completed)
âœ“ TRANSCRIBE - Skipped (already completed)
âœ“ PROCESS - Skipped (already completed)
â™»ï¸  TTS - Retrying... (attempt 1/10)
âœ… TTS - SUCCESS!
âœ… YOUTUBE_METADATA - OK
âœ… RENDER - OK
âœ… MERGE - OK
âœ… THUMBNAIL - OK
âœ… UPLOAD - OK
âœ… SHORT - OK
âœ… SHORT_UPLOAD - OK
âœ… FINAL - Complete!
```

---

## Benefits

### 1. **Time Savings**
- â±ï¸ No need to re-run successful stages (can save 20-40 minutes per book)
- â±ï¸ Only retry the failed stage + subsequent stages

### 2. **Resource Savings**
- ğŸ’° No wasted API calls (Gemini, YouTube API, etc.)
- ğŸ’° No duplicate downloads/uploads
- ğŸ’¾ No duplicate video rendering (FFmpeg is slow)

### 3. **Reliability**
- ğŸ”„ Automatic recovery from transient failures:
  - Network timeouts
  - API rate limits
  - Temporary service outages
- ğŸ”„ Intelligent retry with fresh attempts (10 new tries)

### 4. **User Experience**
- âœ… Clear messages about what's happening
- âœ… Visual indicators (â™»ï¸ for retry, âœ“ for skip)
- âœ… No manual intervention needed

---

## Example Failure Scenarios & Recovery

### Scenario A: Network Timeout During TTS
**Failure**:
```
[TTS] Downloading chunk 1/50...
âŒ Network timeout after 20 seconds
[TTS] Retrying (attempt 2/10)...
âŒ Network timeout after 20 seconds
... (8 more failures)
ğŸ›‘ TTS stage failed after 10 attempts
```

**Recovery** (after internet restored):
```bash
python main.py
# System detects failed TTS stage
â™»ï¸  RESUMING FROM FAILED STAGE: tts
âœ… TTS - SUCCESS (internet restored, all chunks downloaded)
âœ… Pipeline continues from YOUTUBE_METADATA...
```

---

### Scenario B: Gemini API Quota Exceeded
**Failure**:
```
[PROCESS] Translating Arabic â†’ English...
âŒ Gemini API error: Quota exceeded
[PROCESS] Retrying (attempt 2/10)...
âŒ Gemini API error: Quota exceeded
... (8 more failures)
ğŸ›‘ PROCESS stage failed after 10 attempts
```

**Recovery** (next day after quota reset):
```bash
python main.py
â™»ï¸  RESUMING FROM FAILED STAGE: process
âœ… PROCESS - SUCCESS (quota reset, translation complete)
âœ… Pipeline continues...
```

---

### Scenario C: YouTube Upload Fails
**Failure**:
```
[UPLOAD] Uploading video to YouTube...
âŒ YouTube API error: Service unavailable (503)
[UPLOAD] Retrying (attempt 2/10)...
âŒ YouTube API error: Service unavailable (503)
... (8 more failures)
ğŸ›‘ UPLOAD stage failed after 10 attempts
```

**Recovery** (after YouTube service restored):
```bash
python main.py
â™»ï¸  RESUMING FROM FAILED STAGE: upload
âœ… UPLOAD - SUCCESS
âœ… SHORT - OK
âœ… SHORT_UPLOAD - OK
âœ… Book marked as "done" in database
```

---

## Technical Details

### summary.json Structure

**After Successful Run**:
```json
{
  "run_id": "2025-10-19_12-34-56_Atomic-Habits",
  "stages": [
    {"name": "search", "status": "ok", "duration_sec": 5.2},
    {"name": "transcribe", "status": "ok", "duration_sec": 45.8},
    {"name": "process", "status": "ok", "duration_sec": 120.5},
    {"name": "tts", "status": "ok", "duration_sec": 180.3},
    {"name": "youtube_metadata", "status": "ok", "duration_sec": 2.1},
    {"name": "render", "status": "ok", "duration_sec": 240.7},
    {"name": "merge", "status": "ok", "duration_sec": 15.2},
    {"name": "thumbnail", "status": "ok", "duration_sec": 3.4},
    {"name": "upload", "status": "ok", "duration_sec": 60.8},
    {"name": "short", "status": "ok", "duration_sec": 90.2},
    {"name": "short_upload", "status": "ok", "duration_sec": 30.1}
  ]
}
```

**After Failed Run** (TTS failed):
```json
{
  "run_id": "2025-10-19_12-34-56_Atomic-Habits",
  "stages": [
    {"name": "search", "status": "ok", "duration_sec": 5.2},
    {"name": "transcribe", "status": "ok", "duration_sec": 45.8},
    {"name": "process", "status": "ok", "duration_sec": 120.5},
    {"name": "tts", "status": "failed", "duration_sec": 300.0}
  ],
  "last_failed_stage": "tts"  â† Added on resume
}
```

**After Successful Resume**:
```json
{
  "run_id": "2025-10-19_12-34-56_Atomic-Habits",
  "stages": [
    {"name": "search", "status": "ok", "duration_sec": 5.2},
    {"name": "transcribe", "status": "ok", "duration_sec": 45.8},
    {"name": "process", "status": "ok", "duration_sec": 120.5},
    {"name": "tts", "status": "failed", "duration_sec": 300.0},
    {"name": "tts", "status": "ok", "duration_sec": 185.1},  â† Retry succeeded
    {"name": "youtube_metadata", "status": "ok", "duration_sec": 2.1},
    {"name": "render", "status": "ok", "duration_sec": 240.7},
    ... (rest of stages)
  ]
}
```

**Note**: Failed stage entry remains in history (for debugging), but new successful entry is added.

---

## Testing Strategy

### Manual Test Cases

#### Test 1: Simulate TTS Failure
1. **Setup**: Disconnect internet during TTS stage
2. **Expected**: TTS fails after 10 retries, pipeline stops
3. **Resume**: Reconnect internet, run `python main.py` with same book
4. **Verify**: 
   - âœ… Prints "RESUMING FROM FAILED STAGE: tts"
   - âœ… Skips search, transcribe, process
   - âœ… Retries TTS with fresh attempts
   - âœ… Continues to subsequent stages

#### Test 2: Simulate Gemini API Failure
1. **Setup**: Remove `secrets/api_key.txt` before PROCESS stage
2. **Expected**: PROCESS fails (no API key)
3. **Resume**: Restore `secrets/api_key.txt`, rerun
4. **Verify**:
   - âœ… Detects failed PROCESS stage
   - âœ… Retries PROCESS successfully
   - âœ… Pipeline completes

#### Test 3: Multiple Failures
1. **Setup**: Fail TTS â†’ Fix â†’ Fail UPLOAD â†’ Fix
2. **Expected**: Resume works for both failures
3. **Verify**:
   - âœ… First resume: TTS retried
   - âœ… Second resume: UPLOAD retried
   - âœ… summary.json shows all attempts

---

## Backward Compatibility

### âœ… Compatible Changes
- Existing `summary.json` files work perfectly
- New function `_get_last_failed_stage()` returns `None` for old runs
- Falls back to normal resume logic (skip completed stages)

### âš ï¸ No Breaking Changes
- Old runs without failures: Resume works as before
- Old runs with failures: Now **benefit** from retry feature!

---

## Limitations & Edge Cases

### Edge Case 1: Manual File Deletion
**Scenario**: User deletes artifact files but not `summary.json`

**Behavior**:
- `_is_stage_completed()` detects missing artifact
- Stage is re-run automatically
- **No issue** - system self-corrects

### Edge Case 2: Corrupted summary.json
**Scenario**: `summary.json` is invalid JSON

**Behavior**:
- `_get_last_failed_stage()` catches exception
- Returns `None` (no failed stage detected)
- Falls back to fresh run
- **Graceful degradation**

### Edge Case 3: Stage Fails Again on Retry
**Scenario**: Failed stage fails again after resume

**Behavior**:
- Stage retries 10 times (as normal)
- Fails again â†’ Saves `status="failed"` again
- Pipeline stops
- User can resume again (infinite retries if needed)

---

## Future Enhancements

### 1. **Smart Retry Delays**
- Exponential backoff for network/API errors
- Immediate retry for non-transient errors

### 2. **Failure Categorization**
```python
{
  "name": "tts",
  "status": "failed",
  "error_type": "network_timeout",  # vs "api_quota" vs "invalid_input"
  "retryable": true
}
```

### 3. **Partial Stage Resume**
- TTS failed at chunk 35/50 â†’ Resume from chunk 35 (not chunk 1)

### 4. **Notification System**
- Email/webhook when stage fails
- Notify when manual intervention needed (non-retryable error)

---

## Related Documentation

- **Stop on Error**: `PIPELINE_STOP_ON_ERROR.md` - How pipeline stops on failures
- **Batch Processing**: `BATCH_PROCESSING.md` - How batches handle failed books
- **Database**: `src/infrastructure/adapters/database.py` - Status tracking

---

**Author**: GitHub Copilot  
**Reviewed by**: User (tarik)  
**Status**: âœ… Production Ready
